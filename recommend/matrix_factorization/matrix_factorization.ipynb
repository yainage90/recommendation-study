{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "추천 시스템에서 SVD와 MF를 같은 의미로 혼동해서 사용하곤 하는데, 실제로는 다르다.\n",
    "SVD, NMF 등에서는 null값을 0이나 평균으로 대체한 후 행렬을 분해한다. 이는 학습에 영향을 주어 학습된 모델이 null값을 0 혹은 평균에 근사하게 예측하도록 한다.\n",
    "실제 추천시스템에서 사용하는 MF에서는 평가가 이루어진 데이터만 사용해서 학습한다.\n",
    "\n",
    "다만 Surprise 패키지에서는 MF가 SVD라는 이름으로 구현되어있음; 혼동하지 말 것"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "유저/아이템 행렬을 최적화시키는 방법에는 대표적으로 SGD와 ALS가 있음\n",
    "\n",
    "1. SGD(Stochastic Gradient Descent)\n",
    "학습데이터를 샘플링해서 예측치와의 오차 제곱을 기울기 방향으로 감소시키는 방식\n",
    "2. ALS(Alternating Least Square)\n",
    "사용자 행렬과 아이템 행렬을 교대로 최적화해 나감. 사용자 행렬을 최적화시킬 때는 아이템 행렬은 고정. 아이템 행렬을 최적화 시킬 때도 마찬가지. 목적함수인 실제 평가값 - 예측 평가값의 오차제곱 함수가 convex(아래로 볼록한 함수)가 아니라 최적화가 느려지는 것을 방지함.\n",
    "\n",
    "surprise의 svd는 최적화 방식으로 SGD를 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.insert(0, f'{os.environ.get(\"HOME\")}/workspace/recommendation-study')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from util.data import DataLoader\n",
    "from util.models import Dataset, RecommendResult\n",
    "from recommend.base import BaseRecommender\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "from surprise import SVD, Reader\n",
    "import pandas as pd\n",
    "from surprise import Dataset as SurpriseDataset\n",
    "from surprise.model_selection import GridSearchCV\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = DataLoader().load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MFRecommender(BaseRecommender):\n",
    "    def train(self, dataset: Dataset, **kwargs):\n",
    "        n_factors = kwargs.get('n_factors', 5)\n",
    "        minimum_num_rating = kwargs.get('minimum_num_rating', 100)\n",
    "        use_bias = kwargs.get('use_bias', False)\n",
    "        learning_rate = kwargs.get('learning_rate', 0.005)\n",
    "        n_epochs = kwargs.get('n_epochs', 50)\n",
    "\n",
    "        self.train_data = dataset.train.groupby('movie_id').filter(lambda x: len(x['movie_id']) >= minimum_num_rating)\n",
    "        reader = Reader(rating_scale=(0.5, 5))\n",
    "        surprise_train_data = SurpriseDataset.load_from_df(\n",
    "            self.train_data[['user_id', 'movie_id', 'rating']], reader\n",
    "        ).build_full_trainset()\n",
    "\n",
    "        mf = SVD(n_factors=n_factors, n_epochs=n_epochs, lr_all=learning_rate, biased=use_bias)\n",
    "        mf.fit(surprise_train_data)\n",
    "\n",
    "        data_test = surprise_train_data.build_anti_testset(None)\n",
    "        self.predictions = mf.test(data_test)\n",
    "\n",
    "    def grid_search(self, dataset: Dataset, param_grid: dict, minimum_num_rating: int = 100):\n",
    "        train_data = dataset.train.groupby('movie_id').filter(lambda x: len(x['movie_id']) >= minimum_num_rating)\n",
    "        reader = Reader(rating_scale=(0.5, 5))\n",
    "        surprise_train_data = SurpriseDataset.load_from_df(\n",
    "            train_data[['user_id', 'movie_id', 'rating']], reader\n",
    "        )\n",
    "\n",
    "        grid = GridSearchCV(SVD, param_grid=param_grid, measures=['rmse', 'mae'], cv=3)\n",
    "        grid.fit(surprise_train_data)\n",
    "\n",
    "        return grid\n",
    "\n",
    "    def get_top_n(self, n: int = 10):\n",
    "        top_n = defaultdict(list)\n",
    "        for uid, iid, r_ui, est, _ in self.predictions:\n",
    "            top_n[uid].append((iid, est))\n",
    "\n",
    "        for uid, estimations in top_n.items():\n",
    "            estimations.sort(key=lambda x: x[1], reverse=True)\n",
    "            top_n[uid] = [x[0] for x in estimations[:n]]\n",
    "\n",
    "        return top_n\n",
    "\n",
    "    def recommend(self, dataset: Dataset, k: int, **kwargs) -> RecommendResult:\n",
    "        pred_user2items = self.get_top_n(n=k)\n",
    "        movie_rating_predict = dataset.test.copy()\n",
    "        for uid, iid, _, est, _ in self.predictions:\n",
    "            movie_rating_predict.loc[(movie_rating_predict['user_id']==uid) & (movie_rating_predict['movie_id']==iid), 'rating_pred'] = est\n",
    "        \n",
    "        movie_rating_predict.fillna(self.train_data.rating.mean(), inplace=True)\n",
    "\n",
    "        return RecommendResult(movie_rating_predict.rating_pred, pred_user2items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8437284503609203\n",
      "{'n_epochs': 30, 'n_factors': 20, 'biased': False}\n"
     ]
    }
   ],
   "source": [
    "recommender = MFRecommender()\n",
    "param_grid = {\n",
    "    'n_epochs': [30, 50],\n",
    "    'n_factors': [5, 10, 20, 50],\n",
    "    'biased': [True, False],\n",
    "}\n",
    "grid = recommender.grid_search(dataset, param_grid=param_grid)\n",
    "print(grid.best_score['rmse'])\n",
    "print(grid.best_params['rmse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8437584055950028\n",
      "{'n_epochs': 30, 'n_factors': 5, 'biased': True}\n"
     ]
    }
   ],
   "source": [
    "recommender = MFRecommender()\n",
    "param_grid = {\n",
    "    'n_epochs': [30, 50],\n",
    "    'n_factors': [5, 10, 20, 50],\n",
    "    'biased': [True, False],\n",
    "}\n",
    "grid = recommender.grid_search(dataset, param_grid=param_grid, minimum_num_rating=300)\n",
    "print(grid.best_score['rmse'])\n",
    "print(grid.best_params['rmse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8612382513875646\n",
      "{'n_epochs': 30, 'n_factors': 5, 'biased': False}\n"
     ]
    }
   ],
   "source": [
    "recommender = MFRecommender()\n",
    "param_grid = {\n",
    "    'n_epochs': [30, 50],\n",
    "    'n_factors': [5, 10, 20, 50],\n",
    "    'biased': [True, False],\n",
    "}\n",
    "grid = recommender.grid_search(dataset, param_grid=param_grid, minimum_num_rating=10)\n",
    "print(grid.best_score['rmse'])\n",
    "print(grid.best_params['rmse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rmse: 1.048, precision@K: 0.011, recall@K: 0.037\n"
     ]
    }
   ],
   "source": [
    "recommender = MFRecommender()\n",
    "recommender.train(dataset, n_epochcs=30, n_factors=20, use_bias=False)\n",
    "metrics = recommender.run_sample()\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rmse: 1.137, precision@K: 0.014, recall@K: 0.047\n"
     ]
    }
   ],
   "source": [
    "recommender = MFRecommender()\n",
    "recommender.train(dataset, n_epochcs=30, n_factors=5, use_bias=True, minimum_num_rating=300)\n",
    "metrics = recommender.run_sample()\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rmse: 1.139, precision@K: 0.016, recall@K: 0.053\n"
     ]
    }
   ],
   "source": [
    "recommender = MFRecommender()\n",
    "recommender.train(dataset, n_epochcs=50, n_factors=5, use_bias=False, minimum_num_rating=300)\n",
    "metrics = recommender.run_sample()\n",
    "print(metrics)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "recommendation-study-kt-Z5Mpg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
